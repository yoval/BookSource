# -*- coding: utf-8 -*-
"""
Created on Mon Apr 18 11:55:42 2022

@author: fuwen
"""

import requests,re
import pandas as pd


def replaceFomat(text: str, word: str, n: int,reverse=False):
    '''å¯¹æ–‡æœ¬ä¸­çš„æŒ‡å®šå•è¯è¿›è¡Œæ ¼å¼åŒ–çš„æ›¿æ¢/æ›¿å›
    Params:
    ---
    text
        è¦æ›¿æ¢çš„æ–‡æœ¬
    word
        ç›®æ ‡å•è¯
    n
        ç›®æ ‡å•è¯çš„åºå·
    reverse
        æ˜¯å¦è¿›è¡Œæ›¿å›
    Return:
    ---
    new_text
        æ›¿æ¢åçš„æ–‡æœ¬
    '''
    # æ„é€ ã€ä¸­é—´å˜é‡ã€‘
    new_text = text[ : ]
    fmt = "<{}>".format(n)
    # æ›¿æ¢
    if reverse is False:
        new_text = new_text.replace(word, fmt)  # æ ¼å¼åŒ–æ›¿æ¢
        return new_text
    # æ›¿å›
    elif reverse is True:
        new_text = new_text.replace(fmt, word)  # å»æ ¼å¼åŒ–æ›¿æ¢
        return new_text
    # è¦æ±‚éæ³•ï¼Œå¼•å‘å¼‚å¸¸
    else:
        raise TypeError
def replaceMulti(text: str, olds: list, news: list):
    '''ä¸€æ¬¡æ›¿æ¢å¤šç»„å­—ç¬¦ä¸²
    Params:
    ---
    text
        è¦æ›¿æ¢çš„æ–‡æœ¬
    olds
        æ—§å­—ç¬¦ä¸²åˆ—è¡¨
    news
        æ–°å­—ç¬¦ä¸²åˆ—è¡¨
    Return:
    ---
    new_text: str
        æ›¿æ¢åçš„æ–‡æœ¬
    '''
    if len(olds) != len(news):
        raise IndexError
    else:
        new_text = text[ : ]
        # æ ¼å¼åŒ–æ›¿æ¢
        i = 0  # å•è¯è®¡æ•°å™¨
        for word in olds:
            i += 1
            new_text = replaceFomat(new_text, word, i)
        # å»æ ¼å¼åŒ–æ›¿å›
        i = 0  # å½’é›¶
        for word in news:
            i += 1
            new_text = replaceFomat(new_text, word, i,True)
        # è¿”å›æ›¿æ¢å¥½çš„æ–‡æœ¬
        return new_text
#æºUrl
bookSourceUrl = 'https://www.bixiabook.com/'
def yuan(bookSourceUrl):
    if bookSourceUrl[-1]=='/':
        bookSourceUrl=bookSourceUrl[:-1]
    if bookSourceUrl[-1]=='/':
        bookSourceUrl=bookSourceUrl[:-1]
    return bookSourceUrl
#ç½‘ç«™åç§°
bookSourceName = 'é£å¢å°è¯´(åˆ†ç±»æœ€å…¨)'
def Name(bookSourceName):
    bookSourceName = bookSourceName.split('(')[0] 
    bookSourceName = bookSourceName.split('ï¼ˆ')[0] 
    return bookSourceName
#æ£€æµ‹ç½‘ç«™æ ‡é¢˜
def Title(bookSourceUrl):
    headers = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari/537.36 Edg/100.0.1185.44'}
    try:
        resp = requests.get(bookSourceUrl,headers=headers,timeout=10)
        #resp = resp.apparent_encoding
        resp.encoding = resp.apparent_encoding 
        html = resp.text
        title = re.findall('<title>(.*?)</title>', html)[0]
    except:
        title = 'æœªé“¾æ¥æˆåŠŸ'
    with open('website.md','a',encoding='utf-8') as f:
        f.write('| %s    | %s    |\n'%(title,bookSourceUrl))
    return title
#Markdownåˆå§‹åŒ–
def md():
    with open('website.md','a',encoding='utf-8') as f:
        f.write('| æ ‡é¢˜    | ç½‘å€    |'+'\n'+' | ---- | ---- | '+'\n')
md()
#ç‰¹æ®Šå­—ç¬¦
olds = ['â“ˆ',' ','â‘¡','ğŸ”¸','â‘ ','â‘¢','â‘®','â‘£','â‘§','â‘¨pp','â‘ª','ğŸ“œ','ğŸ’°', 'ğŸŒ¾', 'ğŸ’«', 'ğŸ’°', 'ğŸ”', 'ğŸ’¡',  'ğŸ³', 'âœ', 'ğŸ§¾' ,'ğŸ“’' ,'â˜†' ,'ğŸˆ²' ,'ğŸ“–', 'â', 'â˜˜ï¸','ğŸ“—','ğŸ“™',
        'ğŸ©','ğŸ‰','ğŸ·','ğŸŒ¸','ğŸ…','ğŸŠ','ğŸ‘','ğŸˆ','ğŸ”¥','ğŸ“š','ğŸ“°','ğŸ’œ','ğŸ“¥','ğŸ’—','ğŸ”°','ğŸ‘¿']
news = ['' for i in olds]

url = 'https://shuyuan.mgz6.cc/shuyuan/dfab9780b5df159a208ad38e9f369db9.json'
data = pd.read_json(url)
rows = data.shape[0]
print('æ£€æµ‹åˆ°%sæ¡æ•°æ®'%rows)
#æºæ³¨é‡ŠComment
data['bookSourceComment'] = ''
#data['bookSourceComment'] = [Title(bookSourceUrl) for bookSourceUrl in data['bookSourceUrl']]
#åˆ é™¤bookSourceUrl ç­¾å
data['bookSourceUrl'] =[ i.split('#')[0] for i in data['bookSourceUrl']]
#ä¹¦æºåæ›¿æ¢
data['bookSourceName'] = [replaceMulti(i, olds, news) for i in data['bookSourceName'] ]
data['bookSourceName'] = [Name(i) for i in data['bookSourceName']]
#ä¿®æ”¹åˆ†ç»„
bookSourceList = []
for bookSource in data['bookSourceGroup'] :
    if bookSource =='':
        bookSource = 'ä¸€èˆ¬ä¹¦æº'
    bookSourceList.append(bookSource)
data['bookSourceGroup']  = bookSourceList
#æºURL
data['bookSourceUrl'] =[yuan(i) for i in data['bookSourceUrl']]

#åˆ é™¤æœç´¢é“¾æ¥ä¸ºç©ºçš„æº
for row in data.itertuples():
    searchUrl = row.searchUrl
    if searchUrl == '':
        data.drop(row.Index, inplace=True)
#ç²¾ç®€æº
bookUrlPatternList = [] #ä¹¦ç±Urlæ­£åˆ™
exploreUrlList = [] #å‘ç°
loginUrlList = [] #ç™»å½•
searchUrlList = [] #æœç´¢
for row in data.itertuples():
    bookSourceUrl = row.bookSourceUrl
    bookUrlPattern = row.bookUrlPattern
    try:
        bookUrlPattern = bookUrlPattern.replace(bookSourceUrl,'')
    except:
        bookUrlPattern = ''
    bookUrlPatternList.append(bookUrlPattern)
    loginUrl = row.loginUrl
    try:
        loginUrl = loginUrl.replace(bookSourceUrl,'')
    except:
        loginUrl = ''
    loginUrlList.append(loginUrl)
    searchUrl = row.searchUrl
    try:
        searchUrl = searchUrl.replace(bookSourceUrl,'')
    except:
        searchUrl = ''
    searchUrlList.append(searchUrl)
    exploreUrl = row.exploreUrl
    try:
        exploreUrl = exploreUrl.replace(bookSourceUrl,'')
    except:
        exploreUrl = ''
    exploreUrlList.append(exploreUrl)
data['bookUrlPattern'] = bookUrlPatternList
data['exploreUrl'] = exploreUrlList
data['searchUrl'] = searchUrlList
data['loginUrl'] = loginUrlList


#åˆ é™¤æºUrlç›¸åŒæ•°å€¼
data = data.drop_duplicates('bookSourceUrl',keep='first')
#ä¿å­˜
data.to_json('bookSource.json',orient='records',force_ascii=False,lines=False,indent=4)
#s = [Title(bookSourceUrl) for bookSourceUrl in data['bookSourceUrl']]
